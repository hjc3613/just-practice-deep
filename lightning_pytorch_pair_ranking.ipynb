{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hemmat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lorfDFpQFArcslvu4BFQU-ia09xcAqXi",
      "authorship_tag": "ABX9TyPobmwasvoXLYLyMaoIZXxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/lightning_pytorch_pair_ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxTEcSuqb5zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/Thesis/phase-2/history_sentence_pairs_train.csv ./train.csv\n",
        "!cp /content/drive/My\\ Drive/Thesis/phase-2/history_sentence_pairs_valid.csv ./valid.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIFyGdNZyEty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6b98b4a-b4ab-4186-878e-54080b9aa336"
      },
      "source": [
        "!pip -q install transformers\n",
        "!pip install -q  pytorch-lightning\n",
        "!pip install -U tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.43.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PymuvHxhtB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "410aaaf1-5c1e-4e69-e4dc-8c26c50d671b"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0dr_GlcwnU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, json_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            json_file (string): Path to the json file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = pd.read_csv(json_file)\n",
        "        \n",
        "\n",
        "        s = (self.dialogues.true_sentence.str.len() + self.dialogues.history.str.len()).sort_values().index\n",
        "        self.dialogues = self.dialogues.reindex(s)\n",
        "        s = (self.dialogues.false_sentence.str.len() + self.dialogues.history.str.len()).sort_values().index\n",
        "        self.dialogues = self.dialogues.reindex(s)\n",
        "\n",
        "\n",
        "        self.dialogues.dropna(inplace=True)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def truncuate_join_pair_sentence(self, sentence1, sentence2, max_len=510):\n",
        "\n",
        "        \"\"\"\n",
        "        truncuate sentence one from head and sentence two from tail\n",
        "        Args:\n",
        "            sentence1 (string): first sentence\n",
        "            sentence2 (string): seconde sentence\n",
        "        \"\"\"\n",
        "        temp1 = tokenizer.encode(sentence1,add_special_tokens=False)\n",
        "        temp2 = tokenizer.encode(sentence2,add_special_tokens=False)\n",
        "        ### two above line may cause warning but no problem because we've handle them below\n",
        "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "        seq_1 = temp1\n",
        "        seq_2 = temp2\n",
        "        num_tokens_to_remove = len(temp1) + len(temp2) + 3 - max_len\n",
        "        if num_tokens_to_remove > 0 :\n",
        "            seq_1, seq_2, _ = tokenizer.truncate_sequences(temp1[::-1],temp2, num_tokens_to_remove=num_tokens_to_remove)\n",
        "            seq_1.reverse()\n",
        "        result_list = [tokenizer.cls_token_id]+seq_1+[tokenizer.sep_token_id]+seq_2+[tokenizer.sep_token_id]\n",
        "        return result_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history = self.dialogues.iloc[idx].history\n",
        "        true_sentence = self.dialogues.iloc[idx].true_sentence\n",
        "        false_sentence = self.dialogues.iloc[idx].false_sentence\n",
        "\n",
        "\n",
        "        true_pair = self.truncuate_join_pair_sentence(history, true_sentence)\n",
        "        false_pair = self.truncuate_join_pair_sentence(history, false_sentence)\n",
        "        \n",
        "        \n",
        "\n",
        "        true_pair = torch.LongTensor(true_pair)\n",
        "        false_pair = torch.LongTensor(false_pair)\n",
        "\n",
        "        sample = {'true_pair': true_pair, 'false_pair': false_pair}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty0Wea_DfQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyDataset('train.csv')\n",
        "valid_dataset = MyDataset('valid.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeM6HMxbqeGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_true_pair = max([len(data['true_pair']) for data in batch])\n",
        "  max_len_false_pair = max([len(data['false_pair']) for data in batch])\n",
        "  \n",
        "  padding_ind = 0 ## for bert is 0\n",
        "  result_true_pair = torch.zeros(len_batch, max_len_true_pair)\n",
        "  result_false_pair = torch.zeros(len_batch, max_len_false_pair)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['true_pair'])\n",
        "    result_true_pair[i, :p1] = data['true_pair']\n",
        "    p2 = len(data['false_pair'])\n",
        "    result_false_pair[i, :p2] = data['false_pair']\n",
        "\n",
        "\n",
        "  return result_true_pair.long(), result_false_pair.long()\n",
        "\n",
        "sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=128, sampler=sampler,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn)\n",
        "\n",
        "valid_sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
        "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, sampler=valid_sampler,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bymvPN2Xw-fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class CoolSystem(pl.LightningModule):\n",
        " \n",
        "    def __init__(self):\n",
        "        super(CoolSystem, self).__init__()\n",
        "        # not the best model...\n",
        "        self.bert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.fc = nn.Linear(768,1)\n",
        "\n",
        "        for p in self.bert.transformer.layer[:-1].parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "        for p in self.bert.embeddings.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "        nn.init.normal_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        temp = x\n",
        "        temp = self.bert(temp)[0]\n",
        "        temp = temp[:,0,:]\n",
        "        temp = self.fc(temp)\n",
        "        return temp\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # REQUIRED\n",
        "\n",
        "        true_pair, false_pair = batch\n",
        "        batch_size = true_pair.shape[0]\n",
        "        true_sml = self.forward(true_pair)\n",
        "        false_sml = self.forward(false_pair)\n",
        "\n",
        "        criterion = torch.nn.MarginRankingLoss(margin=1)\n",
        "        y_batch_tensor = torch.ones(batch_size)\n",
        "        if self.on_gpu:\n",
        "                y_batch_tensor = y_batch_tensor.cuda(true_pair.device.index)\n",
        "        loss = criterion(true_sml, false_sml, y_batch_tensor)\n",
        "\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # OPTIONAL\n",
        "        true_pair, false_pair = batch\n",
        "        batch_size = true_pair.shape[0]\n",
        "        true_sml = self.forward(true_pair)\n",
        "        false_sml = self.forward(false_pair)\n",
        "\n",
        "        total_num = false_sml.size()[0]\n",
        "\n",
        "\n",
        "        z = true_sml - false_sml\n",
        "        num_err = z[z<0].size()[0]\n",
        "\n",
        "        return {'num_err': num_err, 'total_num':total_num}\n",
        "\n",
        "    def validation_end(self, outputs):\n",
        "        # OPTIONAL\n",
        "        total_err = sum([x['num_err'] for x in outputs])\n",
        "        total_num = sum([x['total_num'] for x in outputs])\n",
        "        tensorboard_logs = {'total_err': total_err}\n",
        "        print(\"Epoch complete, total error is: {} from {}\".format(total_err, total_num))\n",
        "        return {'total_err': total_err, 'log': tensorboard_logs}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # REQUIRED\n",
        "        # can return multiple optimizers and learning_rate schedulers\n",
        "        # (LBFGS it is automatically supported, no need for closure function)\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
        "\n",
        "    @pl.data_loader\n",
        "    def train_dataloader(self):\n",
        "        # REQUIRED\n",
        "        return dataset_loader\n",
        "    \n",
        "    @pl.data_loader\n",
        "    def val_dataloader(self):\n",
        "        # OPTIONAL\n",
        "        return valid_dataset_loader\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjUVk0b26R67",
        "colab_type": "code",
        "outputId": "4c6f1713-a150-4bb6-f431-efc5ff4ecb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "model = CoolSystem()\n",
        "\n",
        "# most basic trainer, uses good defaults\n",
        "trainer = Trainer(gpus=[0], accumulate_grad_batches=16)    \n",
        "\n",
        "trainer.fit(model)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.587f67ec28c540f4294c9c2ac7dcf7841ff371aeb12cdeb6a17f69da39ad9452\n",
            "INFO:transformers.configuration_utils:Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"dim\": 768,\n",
            "  \"do_sample\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"temperature\": 1.0,\n",
            "  \"tie_weights_\": true,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
            "INFO:root:gpu available: True, used: True\n",
            "INFO:root:VISIBLE GPUS: 0\n",
            "INFO:root:\n",
            "                                          Name             Type Params\n",
            "0                                         bert  DistilBertModel   66 M\n",
            "1                              bert.embeddings       Embeddings   23 M\n",
            "2              bert.embeddings.word_embeddings        Embedding   23 M\n",
            "3          bert.embeddings.position_embeddings        Embedding  393 K\n",
            "4                    bert.embeddings.LayerNorm        LayerNorm    1 K\n",
            "..                                         ...              ...    ...\n",
            "82        bert.transformer.layer.5.ffn.dropout          Dropout    0  \n",
            "83           bert.transformer.layer.5.ffn.lin1           Linear    2 M\n",
            "84           bert.transformer.layer.5.ffn.lin2           Linear    2 M\n",
            "85  bert.transformer.layer.5.output_layer_norm        LayerNorm    1 K\n",
            "86                                          fc           Linear  769  \n",
            "\n",
            "[87 rows x 3 columns]\n",
            "                                                                         "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch complete, total error is: 37 from 160\n",
            "Epoch 1:   0%|          | 0/26293 [00:00<?, ?batch/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|          | 295/26293 [03:17<5:06:34,  1.41batch/s, batch_idx=294, gpu=0, loss=1.086, v_num=9]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}