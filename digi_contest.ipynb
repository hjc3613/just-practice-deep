{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digi-contest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/digi_contest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDfLKgBAOCn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxb0vhMdO6nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "    \n",
        "    self.hid_size = hid_size\n",
        "    self.pf_size = pf_size\n",
        "    self.max_len = max_len\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, hid_size)\n",
        "\n",
        "    self.position_enc = nn.Embedding(self.max_len, self.hid_size)\n",
        "    self.position_enc.weight.data = self.position_encoding_init(self.max_len, self.hid_size)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.hid_size])).to(device)\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(self.hid_size)\n",
        "    self.encoder_layer = nn.TransformerEncoderLayer(d_model=hid_size, nhead = n_head, dim_feedforward = pf_size)\n",
        "    self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers, norm=self.layer_norm)\n",
        "    self.fc = nn.Linear(hid_size, 2)\n",
        "\n",
        "    self._init_weights()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    sent_len, batch_size = x.shape[0], x.shape[1]\n",
        "\n",
        "    temp = x\n",
        "    temp = self.embedding(temp)\n",
        "\n",
        "    pos = torch.arange(0,sent_len).unsqueeze(1).repeat(1,batch_size).to(self.device)\n",
        "    temp_pos_emb = self.position_enc(pos)\n",
        "\n",
        "    temp = temp * self.scale + temp_pos_emb\n",
        "    temp = self.encoder(temp)\n",
        "    temp = self.fc(temp[0,:])\n",
        "    return temp\n",
        "\n",
        "  def _init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def append_decoder_layer(self):\n",
        "    appended_mod = nn.TransformerEncoderLayer(d_model=self.hid_size, nhead = self.n_head, dim_feedforward = self.pf_size).to(self.device)\n",
        "    for p in appended_mod.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "    self.encoder.layers.append(appended_mod)\n",
        "    self.encoder.num_layers += 1\n",
        "\n",
        "  \n",
        "  def position_encoding_init(self, n_position, d_pos_vec):\n",
        "    ''' Init the sinusoid position encoding table '''\n",
        "\n",
        "    # keep dim 0 for padding token position encoding zero vector\n",
        "    position_enc = np.array([\n",
        "        [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
        "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "\n",
        "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
        "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
        "    temp = torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
        "    temp = temp.to(self.device)\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN1zAfWNQp9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hid_size = 16\n",
        "vocab_size = 60 \n",
        "n_head = 4\n",
        "n_layers = 2\n",
        "pf_size = 64\n",
        "max_len = 1200\n",
        "model = SentimentModel(hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxDKX-3ZR1JM",
        "colab_type": "code",
        "outputId": "d10a5fff-a6b1-4f62-e2b7-567ca6552c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_len = 20\n",
        "batch_size = 64\n",
        "test_input = torch.LongTensor(test_len, batch_size).random_(1,vocab_size).to(device)\n",
        "model(test_input).shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWnSSADbRsrj",
        "colab_type": "code",
        "outputId": "59a4b2bd-425f-4226-ca7a-641096883283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 30,066 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-APzgvLzS2Dt",
        "colab_type": "text"
      },
      "source": [
        "**Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLR1DH5oS7rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field, SubwordField\n",
        "from torchtext.data import Pipeline\n",
        "import spacy\n",
        "\n",
        "tokenize = lambda x: x.split()\n",
        "\n",
        "def remove_repetitive_char(x):\n",
        "  string = \" \"\n",
        "  for char in x:\n",
        "    if(char != string[-1]):\n",
        "      string += char\n",
        "  return string[1:]\n",
        "\n",
        "def replace_bad_char(x):\n",
        "  string = x\n",
        "  string = string.replace(\"ة\", \"ه\")\n",
        "  string = string.replace(\"ي\", \"ی\")\n",
        "  string = string.replace(\"ٱ\", \"ا\")\n",
        "  string = string.replace(\"ڋ\", \"د\")\n",
        "  string = string.replace(\"ڑ\", \"ر\")\n",
        "  string = string.replace(\"ڪ\", \"ک\")\n",
        "  string = string.replace(\"ھ\", \"ه\")\n",
        "  string = string.replace(\"ی\", \"ی\")\n",
        "  string = string.replace(\"ە\", \"ه\")\n",
        "  string = string.replace(\"ﭘ\", \"پ\")\n",
        "  string = string.replace(\"ﮊ\", \"ژ\")\n",
        "  string = string.replace(\"ﮓ\", \"گ\")\n",
        "  string = string.replace(\"ﮔ\", \"گ\")\n",
        "  string = string.replace(\"ﺎ\", \"گ\")\n",
        "  string = string.replace(\"ﺖ\", \"گ\")\n",
        "  string = string.replace(\"ﺤ\", \"گ\")\n",
        "  string = string.replace(\"ﺪ\", \"گ\")\n",
        "  string = string.replace('ﺮ',\"ر\" )\n",
        "  string = string.replace('ﺯ',\"ز\" )\n",
        "  string = string.replace('ﺰ',\"ز\" )\n",
        "  string = string.replace('ﺳ',\"س\" )\n",
        "  string = string.replace('ﺴ',\"س\" )\n",
        "  string = string.replace('ﺶ', \"ش\")\n",
        "  string = string.replace('ﺷ', \"ش\")\n",
        "  string = string.replace('ﺸ', \"ش\")\n",
        "  string = string.replace('ﺼ', \"ص\")\n",
        "  string = string.replace('ﺽ', \"ض\")\n",
        "  string = string.replace('ﻌ', \"ع\")\n",
        "  string = string.replace('ﻔ', \"ف\")\n",
        "  string = string.replace('ﻗ', \"ق\")\n",
        "  string = string.replace('ﻛ', \"ک\")\n",
        "  string = string.replace('ﻜ', \"ک\")\n",
        "  string = string.replace('ﻝ', \"ل\")\n",
        "  string = string.replace('ﻟ',\"ل\" )\n",
        "  string = string.replace('ﻢ',\"م\" )\n",
        "  string = string.replace('ﻣ', \"م\")\n",
        "  string = string.replace('ﻥ', \"ن\")\n",
        "  string = string.replace('ﻦ', \"ن\")\n",
        "  string = string.replace('ﻧ', \"ن\")\n",
        "  string = string.replace('ﻨ', \"ن\")\n",
        "  string = string.replace('ﻩ', \"ه\")\n",
        "  string = string.replace('ﻪ', \"ه\")\n",
        "  string = string.replace('ﻫ', \"ه\")\n",
        "  string = string.replace('ﻬ', \"ه\")\n",
        "  string = string.replace('ﻭ', \"و\")\n",
        "  string = string.replace('ﻮ', \"و\")\n",
        "  string = string.replace('ﻱ', \"ی\")\n",
        "  string = string.replace('ﻲ', \"ی\")\n",
        "  string = string.replace('ﻳ', \"ی\")\n",
        "  return string\n",
        "  \n",
        "\n",
        "\n",
        "pre_pipe = Pipeline(remove_repetitive_char)\n",
        "pre_pipe.add_before(replace_bad_char)\n",
        "\n",
        "TEXT = Field(sequential=True, tokenize=tokenize, lower=True, preprocessing=pre_pipe, init_token=\"<bos>\")\n",
        "LABEL = Field(sequential=False, use_vocab=False)\n",
        "ID = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "SUBTEXT = SubwordField()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3s7MA_6UXcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
        "                 (\"title\", None), (\"comment\", TEXT),\n",
        "                 (\"rate\", None), (\"verification_status\", LABEL)]\n",
        "\n",
        "tst_datafields = [(\"id\", ID), # we won't be needing the id, so we pass in None as the field\n",
        "                 (\"title\", None), (\"comment\", TEXT),\n",
        "                 (\"rate\", None)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cf8mrIfUxZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def my_filter_pred(example, limited_word = 100):\n",
        "  if(len(example.comment) <= limited_word):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "def my_filter_pred_rand(example, limited_word = 100):\n",
        "  if(len(example.comment) <= limited_word):\n",
        "    if(random.random()<0.4):\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "train_dataset = TabularDataset(\n",
        "               path='train_comments.csv',\n",
        "               format='csv',\n",
        "               skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=tv_datafields,\n",
        "               filter_pred = my_filter_pred)\n",
        "\n",
        "\n",
        "test_dataset = TabularDataset(\n",
        "               path='test_nolabel_comments.csv',\n",
        "               format='csv',\n",
        "               skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=tst_datafields)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxUbobAZVjk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fc6327c-c53a-4776-e122-cef06f46d790"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXl5omx6zarp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = set()\n",
        "for i, batch in enumerate(train_dataset):\n",
        "  s = s.union(set(\" \".join(batch.comment)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftlPS9L_1foE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9951335-23b2-40f4-8346-8c4328a920e5"
      },
      "source": [
        "s"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '¡',\n",
              " '«',\n",
              " '°',\n",
              " '·',\n",
              " '»',\n",
              " '×',\n",
              " '÷',\n",
              " '͢',\n",
              " 'ε',\n",
              " 'κ',\n",
              " 'г',\n",
              " 'ժ',\n",
              " 'հ',\n",
              " 'ձ',\n",
              " 'օ',\n",
              " 'ּ',\n",
              " 'פ',\n",
              " '،',\n",
              " '؛',\n",
              " '\\u061c',\n",
              " '؟',\n",
              " 'ء',\n",
              " 'آ',\n",
              " 'أ',\n",
              " 'ؤ',\n",
              " 'إ',\n",
              " 'ئ',\n",
              " 'ا',\n",
              " 'ب',\n",
              " 'ت',\n",
              " 'ث',\n",
              " 'ج',\n",
              " 'ح',\n",
              " 'خ',\n",
              " 'د',\n",
              " 'ذ',\n",
              " 'ر',\n",
              " 'ز',\n",
              " 'س',\n",
              " 'ش',\n",
              " 'ص',\n",
              " 'ض',\n",
              " 'ط',\n",
              " 'ظ',\n",
              " 'ع',\n",
              " 'غ',\n",
              " 'ـ',\n",
              " 'ف',\n",
              " 'ق',\n",
              " 'ك',\n",
              " 'ل',\n",
              " 'م',\n",
              " 'ن',\n",
              " 'ه',\n",
              " 'و',\n",
              " 'ى',\n",
              " 'ً',\n",
              " 'ٌ',\n",
              " 'ٍ',\n",
              " 'َ',\n",
              " 'ُ',\n",
              " 'ِ',\n",
              " 'ّ',\n",
              " 'ْ',\n",
              " 'ٓ',\n",
              " 'ٔ',\n",
              " 'ٕ',\n",
              " '٠',\n",
              " '١',\n",
              " '٢',\n",
              " '٣',\n",
              " '٤',\n",
              " '٥',\n",
              " '٦',\n",
              " '٧',\n",
              " '٨',\n",
              " '٩',\n",
              " '٪',\n",
              " '٫',\n",
              " '٬',\n",
              " 'ٰ',\n",
              " 'ٵ',\n",
              " 'ٹ',\n",
              " 'پ',\n",
              " 'ڃ',\n",
              " 'چ',\n",
              " 'ڔ',\n",
              " 'ڗ',\n",
              " 'ژ',\n",
              " 'ک',\n",
              " 'گ',\n",
              " 'ۀ',\n",
              " 'ہ',\n",
              " 'ۂ',\n",
              " 'ی',\n",
              " 'ے',\n",
              " '۔',\n",
              " '۰',\n",
              " '۱',\n",
              " '۲',\n",
              " '۳',\n",
              " '۴',\n",
              " '۵',\n",
              " '۶',\n",
              " '۷',\n",
              " '۸',\n",
              " '۹',\n",
              " 'ܢ',\n",
              " 'ݪ',\n",
              " '২',\n",
              " 'ო',\n",
              " '\\u200b',\n",
              " '\\u200c',\n",
              " '\\u200d',\n",
              " '\\u200e',\n",
              " '\\u200f',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '•',\n",
              " '…',\n",
              " '\\u202b',\n",
              " '\\u202d',\n",
              " '‰',\n",
              " '›',\n",
              " '\\u2066',\n",
              " '\\u2069',\n",
              " '⁶',\n",
              " '℅',\n",
              " '●',\n",
              " '☆',\n",
              " '☠',\n",
              " '☹',\n",
              " '☺',\n",
              " '♀',\n",
              " '♂',\n",
              " '♡',\n",
              " '♥',\n",
              " '⚘',\n",
              " '⚜',\n",
              " '⚡',\n",
              " '✅',\n",
              " '✊',\n",
              " '✋',\n",
              " '✌',\n",
              " '❤',\n",
              " '➖',\n",
              " '⬆',\n",
              " '⭐',\n",
              " '⭕',\n",
              " '《',\n",
              " '》',\n",
              " 'ﮐ',\n",
              " 'ﯾ',\n",
              " '﷼',\n",
              " '️',\n",
              " 'ﺏ',\n",
              " 'ﺑ',\n",
              " 'ﺗ',\n",
              " 'ﺘ',\n",
              " 'ﺞ',\n",
              " 'ﺧ',\n",
              " 'ﺨ',\n",
              " 'ﺩ',\n",
              " 'ﺭ',\n",
              " 'ﺲ',\n",
              " 'ﺹ',\n",
              " 'ﺻ',\n",
              " 'ﻃ',\n",
              " 'ﻄ',\n",
              " 'ﻋ',\n",
              " 'ﻓ',\n",
              " 'ﻘ',\n",
              " 'ﻙ',\n",
              " 'ﻤ',\n",
              " 'ﻴ',\n",
              " 'ﻼ',\n",
              " '：'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ySiwxdGVMoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34f2ef17-5b62-42a8-a818-e8418a9ca63e"
      },
      "source": [
        "train_dataset[0].__dict__.keys()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['comment', 'verification_status'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmoJUBu8Vlmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35562c8a-92b1-48b7-a70b-d67c841d6e43"
      },
      "source": [
        "train_dataset[0].verification_status"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdhjcHJrWBsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_dataset, min_freq=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O31x-kv6WGfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afc612e4-fd19-4096-93c7-dfea48eca7dd"
      },
      "source": [
        "len(TEXT.vocab)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WAHfoauWJKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import BucketIterator, interleave_keys, Iterator\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "train_iterator = BucketIterator(dataset= train_dataset, batch_size=batch_size,\n",
        "                                device=device,\n",
        "                                sort_key=lambda x: len(x.comment),\n",
        "                                sort = True,\n",
        "                                shuffle = True,\n",
        "                                repeat = False)\n",
        "\n",
        "test_iter = Iterator(test_dataset, batch_size=1, device=device, sort=False, sort_within_batch=False, repeat=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Lpa1fzXKL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8919e2f-e37f-4b08-e38f-2e51901299e5"
      },
      "source": [
        "for batch in iter(train_iterator):\n",
        "  print(batch.comment.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 512])\n",
            "torch.Size([2, 512])\n",
            "torch.Size([2, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([3, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([5, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([7, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([9, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([10, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([11, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([12, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([13, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([14, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([15, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([17, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([18, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([19, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([20, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([21, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([22, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([23, 512])\n",
            "torch.Size([24, 512])\n",
            "torch.Size([24, 512])\n",
            "torch.Size([24, 512])\n",
            "torch.Size([24, 512])\n",
            "torch.Size([24, 512])\n",
            "torch.Size([25, 512])\n",
            "torch.Size([25, 512])\n",
            "torch.Size([25, 512])\n",
            "torch.Size([25, 512])\n",
            "torch.Size([25, 512])\n",
            "torch.Size([26, 512])\n",
            "torch.Size([26, 512])\n",
            "torch.Size([26, 512])\n",
            "torch.Size([26, 512])\n",
            "torch.Size([26, 512])\n",
            "torch.Size([27, 512])\n",
            "torch.Size([27, 512])\n",
            "torch.Size([27, 512])\n",
            "torch.Size([27, 512])\n",
            "torch.Size([27, 512])\n",
            "torch.Size([28, 512])\n",
            "torch.Size([28, 512])\n",
            "torch.Size([28, 512])\n",
            "torch.Size([28, 512])\n",
            "torch.Size([29, 512])\n",
            "torch.Size([29, 512])\n",
            "torch.Size([29, 512])\n",
            "torch.Size([29, 512])\n",
            "torch.Size([29, 512])\n",
            "torch.Size([30, 512])\n",
            "torch.Size([30, 512])\n",
            "torch.Size([30, 512])\n",
            "torch.Size([30, 512])\n",
            "torch.Size([31, 512])\n",
            "torch.Size([31, 512])\n",
            "torch.Size([31, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([33, 512])\n",
            "torch.Size([33, 512])\n",
            "torch.Size([33, 512])\n",
            "torch.Size([34, 512])\n",
            "torch.Size([34, 512])\n",
            "torch.Size([34, 512])\n",
            "torch.Size([34, 512])\n",
            "torch.Size([35, 512])\n",
            "torch.Size([35, 512])\n",
            "torch.Size([35, 512])\n",
            "torch.Size([36, 512])\n",
            "torch.Size([36, 512])\n",
            "torch.Size([36, 512])\n",
            "torch.Size([37, 512])\n",
            "torch.Size([37, 512])\n",
            "torch.Size([37, 512])\n",
            "torch.Size([38, 512])\n",
            "torch.Size([38, 512])\n",
            "torch.Size([39, 512])\n",
            "torch.Size([39, 512])\n",
            "torch.Size([39, 512])\n",
            "torch.Size([40, 512])\n",
            "torch.Size([40, 512])\n",
            "torch.Size([41, 512])\n",
            "torch.Size([41, 512])\n",
            "torch.Size([41, 512])\n",
            "torch.Size([42, 512])\n",
            "torch.Size([42, 512])\n",
            "torch.Size([43, 512])\n",
            "torch.Size([43, 512])\n",
            "torch.Size([44, 512])\n",
            "torch.Size([44, 512])\n",
            "torch.Size([45, 512])\n",
            "torch.Size([45, 512])\n",
            "torch.Size([46, 512])\n",
            "torch.Size([46, 512])\n",
            "torch.Size([47, 512])\n",
            "torch.Size([47, 512])\n",
            "torch.Size([48, 512])\n",
            "torch.Size([48, 512])\n",
            "torch.Size([49, 512])\n",
            "torch.Size([49, 512])\n",
            "torch.Size([50, 512])\n",
            "torch.Size([51, 512])\n",
            "torch.Size([51, 512])\n",
            "torch.Size([52, 512])\n",
            "torch.Size([53, 512])\n",
            "torch.Size([53, 512])\n",
            "torch.Size([54, 512])\n",
            "torch.Size([55, 512])\n",
            "torch.Size([56, 512])\n",
            "torch.Size([57, 512])\n",
            "torch.Size([57, 512])\n",
            "torch.Size([58, 512])\n",
            "torch.Size([59, 512])\n",
            "torch.Size([60, 512])\n",
            "torch.Size([61, 512])\n",
            "torch.Size([62, 512])\n",
            "torch.Size([63, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([65, 512])\n",
            "torch.Size([66, 512])\n",
            "torch.Size([68, 512])\n",
            "torch.Size([69, 512])\n",
            "torch.Size([70, 512])\n",
            "torch.Size([71, 512])\n",
            "torch.Size([73, 512])\n",
            "torch.Size([74, 512])\n",
            "torch.Size([76, 512])\n",
            "torch.Size([77, 512])\n",
            "torch.Size([79, 512])\n",
            "torch.Size([81, 512])\n",
            "torch.Size([83, 512])\n",
            "torch.Size([85, 512])\n",
            "torch.Size([87, 512])\n",
            "torch.Size([90, 512])\n",
            "torch.Size([92, 512])\n",
            "torch.Size([95, 512])\n",
            "torch.Size([98, 512])\n",
            "torch.Size([101, 508])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqOXFm6yY5iF",
        "colab_type": "text"
      },
      "source": [
        "**train section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc3grY0nYRN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "hid_size = 128\n",
        "pf_size = 256\n",
        "n_head = 8\n",
        "n_layer= 3\n",
        "model = SentimentModel(hid_size, vocab_size, n_head, n_layers, pf_size, max_len, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be1-YiJFZEpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89a9358b-742a-4c48-aee7-43f051c7357e"
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,396,418 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNtmJR2vZYQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdMSTuWTZdQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_one_epoch(model,train_iter, optimizer, criterion, clip):\n",
        "  epoch_loss = 0\n",
        "  model.train()\n",
        "  for batch in tqdm(train_iter):\n",
        "    optimizer.zero_grad()\n",
        "    batch_text = batch.comment\n",
        "    batch_target = batch.verification_status\n",
        "    result = model(batch_text)\n",
        "    loss = criterion(result, batch_target.view(-1))\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(train_iter)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJtLhqaeZpMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_iter, optimizer, criterion, clip, N_EPOCH):\n",
        "  for epoch in range(N_EPOCH):\n",
        "    epoch_loss = train_one_epoch(model, train_iter, optimizer, criterion, clip)\n",
        "    print(\"epoch is {} loss is {}\".format(epoch, epoch_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ7SCLhRZp9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "6a0f28c1-de1e-4f86-8245-0bc0cb7495b7"
      },
      "source": [
        "optimizer = NoamOpt(hid_size, 1, 2000,\n",
        "              torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "train(model, train_iterator, optimizer, criterion, 1, 50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 337/337 [00:26<00:00,  2.52it/s]\n",
            "  0%|          | 1/337 [00:00<00:39,  8.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch is 0 loss is 0.33566401872330676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 180/337 [00:07<00:09, 17.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-59804ea8378a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-4e01b95afaad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_iter, optimizer, criterion, clip, N_EPOCH)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch is {} loss is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1b7ee3f55c06>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_iter, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJRCPs3g5iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds = []\n",
        "with torch.no_grad():\n",
        "  for batch in iter(test_iter):\n",
        "    row_id = batch.id.item()\n",
        "    if(batch.comment.shape[0]==0):\n",
        "      res_out = 0\n",
        "      test_preds.append([row_id,res_out])\n",
        "      continue\n",
        "    res = model(batch.comment)\n",
        "    res_out = torch.argmax(res).item()\n",
        "    test_preds.append([row_id,res_out])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQJV0UMSs3ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds.sort(key=lambda x: x[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAeQu7MGD6CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "df = pandas.DataFrame(test_preds, columns= ['id', 'verification_status'])\n",
        "df.to_csv(\"./file.csv\", sep=',',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm9jh2sHNcyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.append_decoder_layer()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}