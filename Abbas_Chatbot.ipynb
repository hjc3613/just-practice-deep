{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bradley_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/Abbas_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45uNP7CfX7Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "import spacy\n",
        "\n",
        "from spacy.symbols import ORTH\n",
        "my_tok = spacy.load('en')\n",
        "\n",
        "def spacy_tok(x):\n",
        "    return [tok.text for tok in my_tok.tokenizer(x)]\n",
        "\n",
        "QUERY = Field(lower=True, tokenize=spacy_tok)\n",
        "RESPONSE = Field(lower=True, tokenize=spacy_tok, is_target=True, init_token='<bos>', eos_token='<eos>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gmmeZHvZl73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available:\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8HlpeMbZnz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_tok.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"n't\"}])\n",
        "my_tok.tokenizer.add_special_case(\"can't\", [{ORTH: \"can\"}, {ORTH: \"not\"}])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dy7TSTGZpoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "train_dataset = TabularDataset(path=\"./formatted_movie_lines.txt\", format=\"CSV\",\n",
        "                               fields=[(\"query\", QUERY),(\"response\", RESPONSE)],\n",
        "                               csv_reader_params={\"delimiter\":'\\t'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv-wQRDlNvgM",
        "colab_type": "code",
        "outputId": "87338eb6-49e2-4926-c9b8-6c941389edcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "QUERY.build_vocab(train_dataset)\n",
        "RESPONSE.build_vocab(train_dataset)\n",
        "print(\"id of 'film' in query vocab is {}\".format(QUERY.vocab.stoi['film']))\n",
        "print(\"word of id=33 in query vocab is '{}'\".format(QUERY.vocab.itos[33]))\n",
        "print(\"len of Query vocab is {}\".format(len(QUERY.vocab)))\n",
        "print(\"len of Response vocab is {}\".format(len(RESPONSE.vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id of 'film' in query vocab is 1059\n",
            "word of id=33 in query vocab is 'know'\n",
            "len of Query vocab is 48505\n",
            "len of Response vocab is 49036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--vxBRleA8PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef433bf7-9285-4b26-a1d0-75dd98dfef56"
      },
      "source": [
        "print(\"number of rows in train data is {}\".format(len(train_dataset)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of rows in train data is 221282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfPkNvi_B1gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d996fb2c-583b-4558-92e8-c0a735a1d3ea"
      },
      "source": [
        "from torchtext.data import Dataset\n",
        "\n",
        "def my_filter_pred(example, limited_word = 3):\n",
        "  if(len(example.query) < limited_word and len(example.response) < limited_word):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "phase_train_dataset = Dataset(examples = train_dataset.examples,\n",
        "               fields=[(\"query\", QUERY),(\"response\", RESPONSE)],\n",
        "               filter_pred = my_filter_pred)\n",
        "\n",
        "print(\"len of this phase_train_dataset is {}\".format(len(phase_train_dataset)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of this phase_train_dataset is 1646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEjDykrEabVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import BucketIterator, interleave_keys\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "train_iterator = BucketIterator(dataset= phase_train_dataset, batch_size=batch_size,\n",
        "                                device=device,\n",
        "                                sort_key=lambda x: interleave_keys(len(x.query), len(x.response)),\n",
        "                                sort = True,\n",
        "                                shuffle = True,\n",
        "                                repeat = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQvdKHxvCZjW",
        "colab_type": "code",
        "outputId": "d307f818-e837-4f2d-f399-f7e916952e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "## test if data loads well?\n",
        "for a in iter(train_iterator):\n",
        "  print(\"response shape : \\t\",a.response.shape)\n",
        "  print(\"query shape :    \\t\",a.query.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "response shape : \t torch.Size([4, 512])\n",
            "query shape :    \t torch.Size([2, 512])\n",
            "response shape : \t torch.Size([4, 512])\n",
            "query shape :    \t torch.Size([2, 512])\n",
            "response shape : \t torch.Size([4, 512])\n",
            "query shape :    \t torch.Size([2, 512])\n",
            "response shape : \t torch.Size([4, 110])\n",
            "query shape :    \t torch.Size([2, 110])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4iHd1PvadmJ",
        "colab_type": "code",
        "outputId": "7d0735d6-f39f-42e1-85fa-7db36cc4b7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "num_batch = 0\n",
        "for batch in (iter(train_iterator)):\n",
        "  num_batch += 1\n",
        "print(\"number of batch is:\", num_batch)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of batch is: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x8xba4xayJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class Abbas(nn.Module):\n",
        "  def __init__(self, src_voc_sze, trg_voc_sze, hid_sze, num_head, num_enc, num_dec):\n",
        "    super(Abbas, self).__init__()\n",
        "    self.hid_sze = hid_sze\n",
        "    self.src_word_embedding = nn.Embedding(src_voc_sze, self.hid_sze)\n",
        "    self.trg_word_embedding = nn.Embedding(trg_voc_sze, self.hid_sze)\n",
        "    self.trg_pos_embedding = nn.Embedding(800, self.hid_sze)\n",
        "    self.num_head = num_head\n",
        "    self.transformer = nn.Transformer(self.hid_sze, self.num_head, num_enc, num_dec)\n",
        "    self.fc = nn.Linear(self.hid_sze, trg_voc_sze)\n",
        "  \n",
        "  def forward(self, src, trg):\n",
        "    #src = [src sent len, batch_size]\n",
        "    #trg = [trg sent len, batch_size]\n",
        "    temp_src = self.src_word_embedding(src)\n",
        "    temp_trg = self.trg_word_embedding(trg)\n",
        "    trg_sent_len, batch_size = trg.shape[0], trg.shape[1]\n",
        "    trg_pos = self.trg_pos_embedding(torch.arange(0, trg_sent_len).unsqueeze(0).\n",
        "                                     repeat(batch_size,1).to(device)).transpose(0,1)\n",
        "    trg_mask = self._generate_square_subsequent_mask(trg_sent_len)\n",
        "    temp_trg = temp_trg + trg_pos\n",
        "    temp = self.transformer(temp_src, temp_trg, tgt_mask=trg_mask)\n",
        "    return self.fc(temp)\n",
        "  \n",
        "  def _generate_square_subsequent_mask(self, sz):\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    mask = mask.to(device)\n",
        "    return mask\n",
        "\n",
        "\n",
        "  def greedy_inference_one_sample(self, src, max_len=20):\n",
        "\n",
        "    self.eval()\n",
        "    with torch.no_grad():\n",
        "      #src = [src sent len]\n",
        "      src_len = src.shape[0]\n",
        "      src = src.unsqueeze(1)\n",
        "      #src = [sent_len, 1]\n",
        "      trg = src.new_full((1,1), RESPONSE.vocab.stoi['<bos>'])\n",
        "      #trg = [1,1]\n",
        "\n",
        "      translation_step = 0\n",
        "      while translation_step < max_len:\n",
        "        out = self.forward(src, trg)\n",
        "        out = out[-1,:]\n",
        "        #out = [batch_size, trg_vocab_size]\n",
        "        nex = out.argmax(dim=1).unsqueeze(0)\n",
        "        #nex = [1, 1]\n",
        "        trg = torch.cat((trg, nex), dim=0)\n",
        "        translation_step += 1\n",
        "    return trg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QgtTbBmcsNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hid_dim = 512\n",
        "src_voc_size = len(QUERY.vocab)\n",
        "trg_voc_size = len(RESPONSE.vocab)\n",
        "num_head = 8\n",
        "num_enc = 6\n",
        "num_dec = 4\n",
        "\n",
        "abbas_model = Abbas(src_voc_sze=src_voc_size, trg_voc_sze=trg_voc_size,\n",
        "                        hid_sze=hid_dim, num_head=num_head,\n",
        "                        num_enc=num_enc, num_dec=num_dec)\n",
        "abbas_model = abbas_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrHmyiE6HMFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd1c2946-2f6f-48e9-c2ef-5e370d8cd5f5"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(abbas_model):,} trainable parameters')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 111,238,540 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S9HHR9lHjc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in abbas_model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqrmC-BkHlG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8hvOmTeGUy",
        "colab_type": "code",
        "outputId": "5e59a20b-cfcb-4cc5-9043-b5699528f4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=RESPONSE.vocab.stoi['<pad>'])\n",
        "optimizer = NoamOpt(hid_dim, 1, 2000,\n",
        "            torch.optim.Adam(abbas_model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "epoch_number = 100\n",
        "\n",
        "for epoch in range(1, epoch_number+1):\n",
        "  epoch_loss = 0\n",
        "  abbas_model.train()\n",
        "  for i, batch in enumerate(iter(train_iterator)):\n",
        "    src = batch.query\n",
        "    trg = batch.response\n",
        "    optimizer.zero_grad()\n",
        "    out = abbas_model(src, trg)\n",
        "    loss = criterion(out[:-1,:].view(-1, out.shape[2]), trg[1:,:].view(-1))\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(abbas_model.parameters(), 0.5)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  avr_epoch_loss = epoch_loss / len(train_iterator)\n",
        "  print(\"epoch {} loss is: {}\".format(epoch, avr_epoch_loss))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 loss is: 9.392859935760498\n",
            "epoch 2 loss is: 9.378726482391357\n",
            "epoch 3 loss is: 9.347369909286499\n",
            "epoch 4 loss is: 9.305662870407104\n",
            "epoch 5 loss is: 9.247285842895508\n",
            "epoch 6 loss is: 9.177646398544312\n",
            "epoch 7 loss is: 9.100929021835327\n",
            "epoch 8 loss is: 9.016826152801514\n",
            "epoch 9 loss is: 8.925750017166138\n",
            "epoch 10 loss is: 8.834258079528809\n",
            "epoch 11 loss is: 8.738357305526733\n",
            "epoch 12 loss is: 8.642095565795898\n",
            "epoch 13 loss is: 8.547211408615112\n",
            "epoch 14 loss is: 8.445712566375732\n",
            "epoch 15 loss is: 8.343979597091675\n",
            "epoch 16 loss is: 8.237195014953613\n",
            "epoch 17 loss is: 8.124429941177368\n",
            "epoch 18 loss is: 8.004160046577454\n",
            "epoch 19 loss is: 7.8751060962677\n",
            "epoch 20 loss is: 7.737109899520874\n",
            "epoch 21 loss is: 7.590033650398254\n",
            "epoch 22 loss is: 7.436927080154419\n",
            "epoch 23 loss is: 7.274193286895752\n",
            "epoch 24 loss is: 7.106865644454956\n",
            "epoch 25 loss is: 6.9355162382125854\n",
            "epoch 26 loss is: 6.765461087226868\n",
            "epoch 27 loss is: 6.580899953842163\n",
            "epoch 28 loss is: 6.397045135498047\n",
            "epoch 29 loss is: 6.21287989616394\n",
            "epoch 30 loss is: 6.0212496519088745\n",
            "epoch 31 loss is: 5.826097846031189\n",
            "epoch 32 loss is: 5.6282230615615845\n",
            "epoch 33 loss is: 5.4265464544296265\n",
            "epoch 34 loss is: 5.222382664680481\n",
            "epoch 35 loss is: 5.018863558769226\n",
            "epoch 36 loss is: 4.813570022583008\n",
            "epoch 37 loss is: 4.610253930091858\n",
            "epoch 38 loss is: 4.4056960344314575\n",
            "epoch 39 loss is: 4.203425168991089\n",
            "epoch 40 loss is: 4.002930581569672\n",
            "epoch 41 loss is: 3.8060109615325928\n",
            "epoch 42 loss is: 3.6127943992614746\n",
            "epoch 43 loss is: 3.4248151779174805\n",
            "epoch 44 loss is: 3.2422003149986267\n",
            "epoch 45 loss is: 3.064567983150482\n",
            "epoch 46 loss is: 2.8950281143188477\n",
            "epoch 47 loss is: 2.7338507175445557\n",
            "epoch 48 loss is: 2.5802550315856934\n",
            "epoch 49 loss is: 2.439210593700409\n",
            "epoch 50 loss is: 2.3022135496139526\n",
            "epoch 51 loss is: 2.179002523422241\n",
            "epoch 52 loss is: 2.070626825094223\n",
            "epoch 53 loss is: 1.9654357731342316\n",
            "epoch 54 loss is: 1.8804838359355927\n",
            "epoch 55 loss is: 1.8072154819965363\n",
            "epoch 56 loss is: 1.7225138247013092\n",
            "epoch 57 loss is: 1.6497959792613983\n",
            "epoch 58 loss is: 1.5802240669727325\n",
            "epoch 59 loss is: 1.5222223699092865\n",
            "epoch 60 loss is: 1.4636812508106232\n",
            "epoch 61 loss is: 1.422793060541153\n",
            "epoch 62 loss is: 1.3629949390888214\n",
            "epoch 63 loss is: 1.30973619222641\n",
            "epoch 64 loss is: 1.2594127655029297\n",
            "epoch 65 loss is: 1.212793618440628\n",
            "epoch 66 loss is: 1.1718102395534515\n",
            "epoch 67 loss is: 1.1305705606937408\n",
            "epoch 68 loss is: 1.0889403373003006\n",
            "epoch 69 loss is: 1.0499054044485092\n",
            "epoch 70 loss is: 1.0155989974737167\n",
            "epoch 71 loss is: 0.9811792969703674\n",
            "epoch 72 loss is: 0.9438847452402115\n",
            "epoch 73 loss is: 0.9105107337236404\n",
            "epoch 74 loss is: 0.8768174201250076\n",
            "epoch 75 loss is: 0.8534185737371445\n",
            "epoch 76 loss is: 0.8163052499294281\n",
            "epoch 77 loss is: 0.7853623926639557\n",
            "epoch 78 loss is: 0.7559595704078674\n",
            "epoch 79 loss is: 0.7303830832242966\n",
            "epoch 80 loss is: 0.703890860080719\n",
            "epoch 81 loss is: 0.6750849857926369\n",
            "epoch 82 loss is: 0.6496174409985542\n",
            "epoch 83 loss is: 0.6242793425917625\n",
            "epoch 84 loss is: 0.6022311672568321\n",
            "epoch 85 loss is: 0.5729009881615639\n",
            "epoch 86 loss is: 0.548543855547905\n",
            "epoch 87 loss is: 0.5269190073013306\n",
            "epoch 88 loss is: 0.50574841350317\n",
            "epoch 89 loss is: 0.48346103727817535\n",
            "epoch 90 loss is: 0.45895572006702423\n",
            "epoch 91 loss is: 0.43740055710077286\n",
            "epoch 92 loss is: 0.42083970457315445\n",
            "epoch 93 loss is: 0.39466311782598495\n",
            "epoch 94 loss is: 0.3751438669860363\n",
            "epoch 95 loss is: 0.3553941212594509\n",
            "epoch 96 loss is: 0.33918844535946846\n",
            "epoch 97 loss is: 0.3189614601433277\n",
            "epoch 98 loss is: 0.29989341273903847\n",
            "epoch 99 loss is: 0.28178392723202705\n",
            "epoch 100 loss is: 0.26660254411399364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58778EVIm9BS",
        "colab_type": "code",
        "outputId": "e47d94a2-b277-430f-fb4a-e04e97a09f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "source_sentence = phase_train_dataset[50].query\n",
        "#source_sentence = ['what','is','?']\n",
        "print(source_sentence)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['pupils', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnxVh2pinJHH",
        "colab_type": "code",
        "outputId": "2d1d1efe-f264-4b34-a3d1-6dee8246ab1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = QUERY.numericalize([source_sentence]).to(device)\n",
        "x = x.flatten()\n",
        "print(x.shape)\n",
        "result = abbas_model.greedy_inference_one_sample(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrrmT-mi-ce3",
        "colab_type": "code",
        "outputId": "bc81993a-834c-4fb9-9a31-24e0b0b53ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "result = result.flatten()\n",
        "for wrd_ind in result:\n",
        "  print(RESPONSE.vocab.itos[wrd_ind])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bos>\n",
            "please\n",
            ".\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EViqMhvoYA8W",
        "colab_type": "code",
        "outputId": "0f0761ff-928c-4484-dd80-14cb1bc54610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "print(RESPONSE.vocab.itos[2])\n",
        "print(RESPONSE.vocab.itos[5])\n",
        "print(RESPONSE.vocab.itos[8])\n",
        "print(RESPONSE.vocab.itos[3])\n",
        "print(RESPONSE.vocab.itos[22])\n",
        "print(RESPONSE.vocab.itos[4])\n",
        "print(RESPONSE.vocab.itos[66])\n",
        "print(RESPONSE.vocab.itos[125])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bos>\n",
            ",\n",
            "?\n",
            "<eos>\n",
            "!\n",
            ".\n",
            "think\n",
            "little\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nclzWr-trMJe",
        "colab_type": "code",
        "outputId": "f9096903-86d3-4f42-aa3c-04280df41261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def batch_index_to_strings(trg):\n",
        "  # trg = [sent_len, batch_size]\n",
        "  temp = trg.transpose(0,1)\n",
        "  for i, row in enumerate(temp):\n",
        "    print(row)\n",
        "\n",
        "batch_index_to_strings(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5le-q6_IrZpa",
        "colab_type": "code",
        "outputId": "bab19e45-c89b-4c1c-bfe4-ced4a1c51c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0f73ca2d8abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sz' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13y2paU7rbA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = (torch.triu(torch.ones(5, 5)) == 1).transpose(0, 1)\n",
        "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10kk8xzZsBvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}