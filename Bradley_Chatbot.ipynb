{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bradley_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/Bradley_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45uNP7CfX7Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "import spacy\n",
        "\n",
        "from spacy.symbols import ORTH\n",
        "my_tok = spacy.load('en')\n",
        "\n",
        "def spacy_tok(x):\n",
        "    return [tok.text for tok in my_tok.tokenizer(x)]\n",
        "\n",
        "QUERY = Field(lower=True, tokenize=spacy_tok)\n",
        "RESPONSE = Field(lower=True, tokenize=spacy_tok, is_target=True, init_token='<bos>', eos_token='<eos>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gmmeZHvZl73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available:\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8HlpeMbZnz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_tok.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"n't\"}])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dy7TSTGZpoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "train_dataset = TabularDataset(path=\"./simpleR21.csv\", format=\"CSV\",\n",
        "                               fields=[(\"query\", QUERY),(\"response\", RESPONSE)],\n",
        "                               csv_reader_params={\"delimiter\":'\\t'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-McqippSZz8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "51ca7bcc-fea8-4b48-f4dd-16e6ff762746"
      },
      "source": [
        "QUERY.build_vocab(train_dataset)\n",
        "RESPONSE.build_vocab(train_dataset)\n",
        "print(QUERY.vocab.stoi['film'])\n",
        "print(QUERY.vocab.itos[33])\n",
        "print(len(QUERY.vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "religion\n",
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEjDykrEabVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import BucketIterator\n",
        "\n",
        "train_iterator = BucketIterator(dataset= train_dataset, batch_size=16\n",
        "                                ,device=device\n",
        "                                ,sort_key=lambda x: data.interleave_keys(len(x.query), len(x.response))\n",
        "                                , repeat = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4iHd1PvadmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "26d1ceef-a1a4-492c-a03d-819d0663498b"
      },
      "source": [
        "for batch in (iter(train_iterator)):\n",
        "  print(batch.query.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 16])\n",
            "torch.Size([6, 16])\n",
            "torch.Size([12, 16])\n",
            "torch.Size([7, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x8xba4xayJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class Bradley(nn.Module):\n",
        "  def __init__(self, src_voc_sze, trg_voc_sze, hid_sze, num_head, num_enc, num_dec):\n",
        "    super(Bradley, self).__init__()\n",
        "    self.hid_sze = hid_sze\n",
        "    self.src_word_embedding = nn.Embedding(src_voc_sze, self.hid_sze)\n",
        "    self.trg_word_embedding = nn.Embedding(trg_voc_sze, self.hid_sze)\n",
        "    self.num_head = num_head\n",
        "    self.transformer = nn.Transformer(self.hid_sze, self.num_head, num_enc, num_dec)\n",
        "    self.fc = nn.Linear(self.hid_sze, trg_voc_sze)\n",
        "  \n",
        "  def forward(self, src, trg):\n",
        "    temp_src = self.src_word_embedding(src)\n",
        "    temp_trg = self.src_word_embedding(trg)\n",
        "    temp = self.transformer(temp_src, temp_trg)\n",
        "    return self.fc(temp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QgtTbBmcsNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bradley_model = Bradley(src_voc_sze=len(QUERY.vocab), trg_voc_sze=len(RESPONSE.vocab),\n",
        "                        hid_sze=256, num_head=4,\n",
        "                        num_enc=4, num_dec=2)\n",
        "bradley_model = bradley_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8hvOmTeGUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "2b31e12c-2e92-44ef-99cf-85caeebaa026"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.5\n",
        "optimizer = torch.optim.SGD(bradley_model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "epoch_number = 10\n",
        "\n",
        "for epoch in range(1, epoch_number+1):\n",
        "  bradley_model.train()\n",
        "  for batch in iter(train_iterator):\n",
        "    src = batch.query\n",
        "    trg = batch.query\n",
        "    out = bradley_model(src, trg)\n",
        "    loss = criterion(out.view(-1, out.shape[2]), trg.view(-1))\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(bradley_model.parameters(), 0.5)\n",
        "    optimizer.step()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.96686315536499\n",
            "3.5264992713928223\n",
            "2.080118179321289\n",
            "3.0013229846954346\n",
            "1.6152182817459106\n",
            "2.7996318340301514\n",
            "1.9602636098861694\n",
            "1.4487637281417847\n",
            "1.5394340753555298\n",
            "1.2498375177383423\n",
            "0.8729048371315002\n",
            "1.1534901857376099\n",
            "0.9681708216667175\n",
            "0.6927459836006165\n",
            "0.7604721784591675\n",
            "0.6124193668365479\n",
            "0.5347681641578674\n",
            "0.6757655143737793\n",
            "0.46241116523742676\n",
            "0.5170096755027771\n",
            "0.3575325012207031\n",
            "0.3833262026309967\n",
            "0.3883305490016937\n",
            "0.2246009260416031\n",
            "0.22116543352603912\n",
            "0.14700908958911896\n",
            "0.2167665958404541\n",
            "0.21887743473052979\n",
            "0.06838489323854446\n",
            "0.13479556143283844\n",
            "0.17004738748073578\n",
            "0.07649350166320801\n",
            "0.04738254472613335\n",
            "0.06227310746908188\n",
            "0.07413377612829208\n",
            "0.031506408005952835\n",
            "0.01874273084104061\n",
            "0.016057291999459267\n",
            "0.02504136599600315\n",
            "0.038459498435258865\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}