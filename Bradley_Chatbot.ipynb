{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bradley_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/Bradley_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45uNP7CfX7Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "import spacy\n",
        "\n",
        "from spacy.symbols import ORTH\n",
        "my_tok = spacy.load('en')\n",
        "\n",
        "def spacy_tok(x):\n",
        "    return [tok.text for tok in my_tok.tokenizer(x)]\n",
        "\n",
        "QUERY = Field(lower=True, tokenize=spacy_tok)\n",
        "RESPONSE = Field(lower=True, tokenize=spacy_tok, is_target=True, init_token='<bos>', eos_token='<eos>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gmmeZHvZl73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available:\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8HlpeMbZnz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_tok.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"n't\"}])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dy7TSTGZpoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "train_dataset = TabularDataset(path=\"./simpleR21.csv\", format=\"CSV\",\n",
        "                               fields=[(\"query\", QUERY),(\"response\", RESPONSE)],\n",
        "                               csv_reader_params={\"delimiter\":'\\t'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-McqippSZz8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "51ca7bcc-fea8-4b48-f4dd-16e6ff762746"
      },
      "source": [
        "QUERY.build_vocab(train_dataset)\n",
        "RESPONSE.build_vocab(train_dataset)\n",
        "print(QUERY.vocab.stoi['film'])\n",
        "print(QUERY.vocab.itos[33])\n",
        "print(len(QUERY.vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "religion\n",
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEjDykrEabVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import BucketIterator\n",
        "\n",
        "train_iterator = BucketIterator(dataset= train_dataset, batch_size=16\n",
        "                                ,device=device\n",
        "                                ,sort_key=lambda x: data.interleave_keys(len(x.query), len(x.response))\n",
        "                                , repeat = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4iHd1PvadmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "26d1ceef-a1a4-492c-a03d-819d0663498b"
      },
      "source": [
        "for batch in (iter(train_iterator)):\n",
        "  print(batch.query.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 16])\n",
            "torch.Size([6, 16])\n",
            "torch.Size([12, 16])\n",
            "torch.Size([7, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x8xba4xayJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class Bradley(nn.Module):\n",
        "  def __init__(self, src_voc_sze, trg_voc_sze, hid_sze, num_head, num_enc, num_dec):\n",
        "    super(Bradley, self).__init__()\n",
        "    self.hid_sze = hid_sze\n",
        "    self.src_word_embedding = nn.Embedding(src_voc_sze, self.hid_sze)\n",
        "    self.trg_word_embedding = nn.Embedding(trg_voc_sze, self.hid_sze)\n",
        "    self.num_head = num_head\n",
        "    self.transformer = nn.Transformer(self.hid_sze, self.num_head, num_enc, num_dec)\n",
        "    self.fc = nn.Linear(self.hid_sze, trg_voc_sze)\n",
        "  \n",
        "  def forward(self, src, trg):\n",
        "    temp_src = self.src_word_embedding(src)\n",
        "    temp_trg = self.src_word_embedding(trg)\n",
        "    temp = self.transformer(temp_src, temp_trg)\n",
        "    return self.fc(temp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QgtTbBmcsNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bradley_model = Bradley(src_voc_sze=len(QUERY.vocab), trg_voc_sze=len(RESPONSE.vocab),\n",
        "                        hid_sze=256, num_head=4,\n",
        "                        num_enc=4, num_dec=2)\n",
        "bradley_model = bradley_model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8hvOmTeGUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "15639e51-50d7-4930-d04b-e1559bebaa28"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=RESPONSE.vocab.stoi['<pad>'])\n",
        "lr = 0.5\n",
        "optimizer = torch.optim.SGD(bradley_model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "epoch_number = 10\n",
        "\n",
        "for epoch in range(1, epoch_number+1):\n",
        "  bradley_model.train()\n",
        "  for batch in iter(train_iterator):\n",
        "    src = batch.query\n",
        "    trg = batch.query\n",
        "    out = bradley_model(src, trg)\n",
        "    loss = criterion(out.view(-1, out.shape[2]), trg.view(-1))\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(bradley_model.parameters(), 0.5)\n",
        "    optimizer.step()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.154428482055664\n",
            "3.9079723358154297\n",
            "3.331676959991455\n",
            "3.0151851177215576\n",
            "2.178809642791748\n",
            "2.5015740394592285\n",
            "1.9549877643585205\n",
            "1.8358585834503174\n",
            "1.3946281671524048\n",
            "1.6510370969772339\n",
            "1.0656342506408691\n",
            "1.4822208881378174\n",
            "1.3972320556640625\n",
            "0.8926560282707214\n",
            "0.9742722511291504\n",
            "0.752997100353241\n",
            "0.8059644103050232\n",
            "0.9954825043678284\n",
            "0.4343242049217224\n",
            "0.5353960990905762\n",
            "0.2735218405723572\n",
            "0.6622867584228516\n",
            "0.722267210483551\n",
            "0.3450008034706116\n",
            "0.30299052596092224\n",
            "0.30385521054267883\n",
            "0.22809918224811554\n",
            "0.4106246829032898\n",
            "0.19677285850048065\n",
            "0.2871069312095642\n",
            "0.1225435733795166\n",
            "0.1825486421585083\n",
            "0.22453446686267853\n",
            "0.10449979454278946\n",
            "0.0790897011756897\n",
            "0.07790741324424744\n",
            "0.07518883049488068\n",
            "0.03419020399451256\n",
            "0.045394983142614365\n",
            "0.024038830772042274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58778EVIm9BS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aaa36976-7dc1-40ca-93b8-4b44c7d7afc4"
      },
      "source": [
        "source_sentence = train_dataset[7].query\n",
        "print(' '.join(source_sentence))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what is your favorite team ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnxVh2pinJHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = QUERY.numericalize([source_sentence]).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}