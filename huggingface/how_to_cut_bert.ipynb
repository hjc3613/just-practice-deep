{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "how_to_cut_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/just-practice-deep/blob/master/huggingface/how_to_cut_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBUCMHTWs1Em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "a355ce66-2f04-40d7-a980-b2549cb9328e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 59.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.40)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=152a2010cb3033d57ea8d4a8c5973db957d053e0524f36a43c0899c6ef039fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYhRWMN_tB9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "73148947-a37a-4aa1-d74c-b1f8be960d56"
      },
      "source": [
        "import torch\n",
        "from transformers import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXpdM-iitJmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X11h07Auxcj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9490229c-5d53-4f09-c23b-4eafc34750f8"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 109,482,240 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSPG-BHaw7JI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0265dbf-bff1-4401-8a83-683f1921105b"
      },
      "source": [
        "type(model.encoder)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.modeling_bert.BertEncoder"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veajQV87uTF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b59bb8b-7e9e-48a8-f066-b38ae2614579"
      },
      "source": [
        "type(model.encoder.layer)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.container.ModuleList"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qTuZDNlxKm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "075bb753-fd92-4746-c104-6ff2e8d77c04"
      },
      "source": [
        "len(model.encoder.layer)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdZwCgl_xTgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model.encoder.layer[3:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P1B7g4fxV2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b516c988-492c-41f1-b360-dc6790463170"
      },
      "source": [
        "len(model.encoder.layer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epMa3X7gxmwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "500321ac-fd88-4e55-fd3e-f4ede104a424"
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 45,691,392 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIuTmiFTyfn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.encoder.layer[0:2].parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIrsBEty3VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in model.embeddings.parameters():\n",
        "  p.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVY0nM7szS7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "0cac18e4-38d2-4e9d-e546-808a5d290bca"
      },
      "source": [
        "for name, p in model.named_parameters():\n",
        "  print(name, p.requires_grad)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings.word_embeddings.weight False\n",
            "embeddings.position_embeddings.weight False\n",
            "embeddings.token_type_embeddings.weight False\n",
            "embeddings.LayerNorm.weight False\n",
            "embeddings.LayerNorm.bias False\n",
            "encoder.layer.0.attention.self.query.weight False\n",
            "encoder.layer.0.attention.self.query.bias False\n",
            "encoder.layer.0.attention.self.key.weight False\n",
            "encoder.layer.0.attention.self.key.bias False\n",
            "encoder.layer.0.attention.self.value.weight False\n",
            "encoder.layer.0.attention.self.value.bias False\n",
            "encoder.layer.0.attention.output.dense.weight False\n",
            "encoder.layer.0.attention.output.dense.bias False\n",
            "encoder.layer.0.attention.output.LayerNorm.weight False\n",
            "encoder.layer.0.attention.output.LayerNorm.bias False\n",
            "encoder.layer.0.intermediate.dense.weight False\n",
            "encoder.layer.0.intermediate.dense.bias False\n",
            "encoder.layer.0.output.dense.weight False\n",
            "encoder.layer.0.output.dense.bias False\n",
            "encoder.layer.0.output.LayerNorm.weight False\n",
            "encoder.layer.0.output.LayerNorm.bias False\n",
            "encoder.layer.1.attention.self.query.weight False\n",
            "encoder.layer.1.attention.self.query.bias False\n",
            "encoder.layer.1.attention.self.key.weight False\n",
            "encoder.layer.1.attention.self.key.bias False\n",
            "encoder.layer.1.attention.self.value.weight False\n",
            "encoder.layer.1.attention.self.value.bias False\n",
            "encoder.layer.1.attention.output.dense.weight False\n",
            "encoder.layer.1.attention.output.dense.bias False\n",
            "encoder.layer.1.attention.output.LayerNorm.weight False\n",
            "encoder.layer.1.attention.output.LayerNorm.bias False\n",
            "encoder.layer.1.intermediate.dense.weight False\n",
            "encoder.layer.1.intermediate.dense.bias False\n",
            "encoder.layer.1.output.dense.weight False\n",
            "encoder.layer.1.output.dense.bias False\n",
            "encoder.layer.1.output.LayerNorm.weight False\n",
            "encoder.layer.1.output.LayerNorm.bias False\n",
            "encoder.layer.2.attention.self.query.weight True\n",
            "encoder.layer.2.attention.self.query.bias True\n",
            "encoder.layer.2.attention.self.key.weight True\n",
            "encoder.layer.2.attention.self.key.bias True\n",
            "encoder.layer.2.attention.self.value.weight True\n",
            "encoder.layer.2.attention.self.value.bias True\n",
            "encoder.layer.2.attention.output.dense.weight True\n",
            "encoder.layer.2.attention.output.dense.bias True\n",
            "encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "encoder.layer.2.intermediate.dense.weight True\n",
            "encoder.layer.2.intermediate.dense.bias True\n",
            "encoder.layer.2.output.dense.weight True\n",
            "encoder.layer.2.output.dense.bias True\n",
            "encoder.layer.2.output.LayerNorm.weight True\n",
            "encoder.layer.2.output.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiSc-qljyyTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d982afac-6c1d-44ca-b154-e753e05f0ded"
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7,678,464 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}